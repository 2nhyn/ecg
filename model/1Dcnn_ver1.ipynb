{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf2202f-1c3e-4763-bc96-dc03877547f4",
   "metadata": {},
   "source": [
    "1dcnn ì‹¤ì‹œ (ì‹¤í—˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ca9033-2a43-4924-8fef-65cf97b1e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install biosppy nolds scikit-learn peakutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae6c60d-05e4-40ac-8521-42a19369128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 07:56:54.690828: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-28 07:56:54.692029: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-28 07:56:54.695811: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-28 07:56:54.705561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743148614.721576     763 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743148614.726372     763 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-28 07:56:54.744382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from wfdb import rdrecord\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from scipy import signal, fft\n",
    "from scipy.signal import spectrogram\n",
    "from biosppy.signals.ecg import christov_segmenter, hamilton_segmenter\n",
    "from nolds import sampen\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import wfdb\n",
    "from wfdb.processing import gqrs_detect\n",
    "from scipy.signal import butter, filtfilt, welch, find_peaks\n",
    "from scipy.stats import entropy\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "import scipy.ndimage\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "from math import atan2, degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8cabc-a632-4fb4-9916-6c0bb094b62b",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì•„í‚¤í…ì³ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d674e75-5e9a-4cc2-b5c1-7ba354e45d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "from tqdm import tqdm\n",
    "import pywt\n",
    "import scipy.ndimage\n",
    "\n",
    "# --- ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---\n",
    "def wavelet_denoise(signal, wavelet='db6', level=4):\n",
    "    try:\n",
    "        coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "        threshold = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "        coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]\n",
    "        return pywt.waverec(coeffs, wavelet)\n",
    "    except:\n",
    "        return signal\n",
    "\n",
    "def oc_co_filter(signal, fs, k_factor):\n",
    "    try:\n",
    "        k_size = int(np.round(k_factor * fs))\n",
    "        struct_elem = np.ones(k_size)\n",
    "        opened = scipy.ndimage.grey_opening(signal, structure=struct_elem)\n",
    "        closed = scipy.ndimage.grey_closing(opened, structure=struct_elem)\n",
    "        return scipy.ndimage.grey_opening(closed, structure=struct_elem)\n",
    "    except:\n",
    "        return signal\n",
    "\n",
    "def bandpass_filter(signal, fs=400, lowcut=0.1, highcut=45):\n",
    "    try:\n",
    "        nyq = 0.5 * fs\n",
    "        b, a = butter(4, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "        return filtfilt(b, a, signal)\n",
    "    except:\n",
    "        return signal\n",
    "\n",
    "# --- ìµœì¢… í†µí•© ì „ì²˜ë¦¬ + padding í•¨ìˆ˜ ---\n",
    "def prepare_ecg_for_cnn(df, lead_index=0, max_len=3000, fs=400, target_col=\"Chagas_label\"):\n",
    "    \"\"\"\n",
    "    Wavelet + Baseline ì œê±° í›„ CNN ì…ë ¥ìš© padding ì ìš©\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"ğŸ”§ CNNìš© ECG ì „ì²˜ë¦¬\"):\n",
    "        signal = row[\"p_signal\"][:, lead_index]\n",
    "        \n",
    "        # âœ… ì „ì²˜ë¦¬: ë°´ë“œíŒ¨ìŠ¤ â†’ ì›¨ì´ë¸”ë¦¿ â†’ ê¸°ì €ì„  ì œê±°\n",
    "        signal = bandpass_filter(signal, fs)\n",
    "        signal = wavelet_denoise(signal)\n",
    "        baseline = oc_co_filter(signal, fs, 0.27)\n",
    "        signal = signal - baseline\n",
    "\n",
    "        # âœ… padding or truncate\n",
    "        if len(signal) >= max_len:\n",
    "            signal = signal[:max_len]\n",
    "        else:\n",
    "            signal = np.pad(signal, (0, max_len - len(signal)), mode='constant')\n",
    "\n",
    "        X.append(signal)\n",
    "        y.append(row[target_col])\n",
    "\n",
    "    X = np.array(X)[..., np.newaxis]  # (batch, time, 1)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "# âœ… ëª¨ë¸ ì •ì˜\n",
    "def build_1d_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(64, kernel_size=5, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(128, kernel_size=5, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# âœ… í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜\n",
    "def train_and_evaluate_1dcnn(df, lead_index=0, max_len=3000):\n",
    "    X, y = prepare_ecg_for_cnn(df, lead_index=lead_index, max_len=max_len)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = build_1d_cnn_model(input_shape=X_train.shape[1:])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # í‰ê°€\n",
    "    y_pred_prob = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_prob > 0.3).astype(int)\n",
    "    \n",
    "    print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"âœ… F1 Score:\", f1_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1200dad-579b-4f75-b372-d1f5d0b5c2ab",
   "metadata": {},
   "source": [
    "### code15 ë°ì´í„° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b380b-e8c5-4644-a17b-4a0c26d4bf71",
   "metadata": {},
   "source": [
    "í”¼ì²˜ ì¶”ì¶œ (lead1: index0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adbe4e5-3ea9-4293-bf35-0c4acc75144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part0 = pd.read_pickle(\"/workspace/my_data/code15_part0.pkl\")\n",
    "# df_part1 = pd.read_pickle(\"/workspace/my_data/code15_part1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3b8dfd-3c97-4db3-8251-72840bb4a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 4 is too high: all coefficients will experience boundary effects.                    | 9155/19901 [00:38<00:45, 235.84it/s]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pywt/_thresholding.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  thresholded = (1 - value/magnitude)\n",
      "ğŸ”§ CNNìš© ECG ì „ì²˜ë¦¬: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19901/19901 [01:23<00:00, 237.37it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 91ms/step - accuracy: 0.9618 - loss: 0.6584 - val_accuracy: 0.9799 - val_loss: 0.4849\n",
      "Epoch 2/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - accuracy: 0.9800 - loss: 0.4465 - val_accuracy: 0.9799 - val_loss: 0.3507\n",
      "Epoch 3/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - accuracy: 0.9792 - loss: 0.3278 - val_accuracy: 0.9799 - val_loss: 0.2672\n",
      "Epoch 4/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 83ms/step - accuracy: 0.9795 - loss: 0.2525 - val_accuracy: 0.9799 - val_loss: 0.2127\n",
      "Epoch 5/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.9783 - loss: 0.2053 - val_accuracy: 0.9799 - val_loss: 0.1763\n",
      "Epoch 6/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.9813 - loss: 0.1668 - val_accuracy: 0.9799 - val_loss: 0.1515\n",
      "Epoch 7/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.9807 - loss: 0.1449 - val_accuracy: 0.9799 - val_loss: 0.1343\n",
      "Epoch 8/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.9813 - loss: 0.1277 - val_accuracy: 0.9799 - val_loss: 0.1223\n",
      "Epoch 9/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - accuracy: 0.9797 - loss: 0.1205 - val_accuracy: 0.9799 - val_loss: 0.1140\n",
      "Epoch 10/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.9816 - loss: 0.1075 - val_accuracy: 0.9799 - val_loss: 0.1084\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
      "âœ… Accuracy: 0.9799045465963325\n",
      "âœ… F1 Score: 0.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3901\n",
      "           1       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.98      3981\n",
      "   macro avg       0.49      0.50      0.49      3981\n",
      "weighted avg       0.96      0.98      0.97      3981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆ: lead_index=0ë²ˆ ë¦¬ë“œ ì‚¬ìš©, ê¸¸ì´ 3000 ê³ ì •\n",
    "model = train_and_evaluate_1dcnn(df_part0, lead_index=0, max_len=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14812a7-66ca-48fd-a71c-7f1904c98eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_code\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_challenge_score  \u001b[38;5;66;03m# í—¬í¼ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ í™•ë¥ ê°’ ì–»ê¸°\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test\u001b[49m)\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# (batch_size, 1) â†’ (batch_size,)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# âœ… Challenge Score ê³„ì‚°\u001b[39;00m\n\u001b[1;32m      7\u001b[0m challenge_score \u001b[38;5;241m=\u001b[39m compute_challenge_score(y_test, y_pred_prob)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "from helper_code import compute_challenge_score  # í—¬í¼ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "# âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ í™•ë¥ ê°’ ì–»ê¸°\n",
    "y_pred_prob = model.predict(X_test).flatten()  # (batch_size, 1) â†’ (batch_size,)\n",
    "\n",
    "# âœ… Challenge Score ê³„ì‚°\n",
    "challenge_score = compute_challenge_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"Challenge Score: {challenge_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8164f9ba-9d65-4456-b39a-50dc48add65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743089047.904966      30 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8752 - loss: 0.3498\n",
      "Epoch 2/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.1156  \n",
      "Epoch 3/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.1206  \n",
      "Epoch 4/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.1163  \n",
      "Epoch 5/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.1077  \n",
      "Epoch 6/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9810 - loss: 0.1054  \n",
      "Epoch 7/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0997  \n",
      "Epoch 8/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.1055  \n",
      "Epoch 9/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.1179  \n",
      "Epoch 10/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.1144  \n",
      "Epoch 11/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.1142  \n",
      "Epoch 12/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.1088  \n",
      "Epoch 13/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.1111  \n",
      "Epoch 14/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.1043  \n",
      "Epoch 15/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.1077  \n",
      "Epoch 16/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9811 - loss: 0.0980  \n",
      "Epoch 17/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.1057  \n",
      "Epoch 18/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.1039  \n",
      "Epoch 19/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.1038  \n",
      "Epoch 20/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.1058  \n",
      "Epoch 21/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9802 - loss: 0.1025  \n",
      "Epoch 22/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9800 - loss: 0.1032  \n",
      "Epoch 23/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9808 - loss: 0.0985  \n",
      "Epoch 24/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.1040  \n",
      "Epoch 25/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.1046  \n",
      "Epoch 26/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.1003  \n",
      "Epoch 27/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.1061  \n",
      "Epoch 28/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.1087  \n",
      "Epoch 29/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.1016  \n",
      "Epoch 30/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.1079  \n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step    \n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Add\n",
    "\n",
    "# âœ… ResNet Block\n",
    "def resnet_block(x, units, dropout_rate=0.3):\n",
    "    shortcut = x  # Residual Connection\n",
    "\n",
    "    x = Dense(units, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(units, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Residual Connection\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "\n",
    "# âœ… ResNet ëª¨ë¸ ìƒì„±\n",
    "def build_resnet(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    x = Dense(128, activation=\"relu\")(inputs)\n",
    "    x = resnet_block(x, 128)\n",
    "    x = resnet_block(x, 128)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)  \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# âœ… ResNet ëª¨ë¸ í•™ìŠµ\n",
    "resnet_model = build_resnet(X_train.shape[1])\n",
    "resnet_model.fit(X_train, y_train, epochs=30, batch_size=64, verbose=1)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ê°’ ìƒì„± (í™•ë¥  ê°’ ì‚¬ìš©)\n",
    "resnet_train_preds = resnet_model.predict(X_train).flatten()\n",
    "resnet_test_preds = resnet_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44190929-f69a-45cd-8241-0c694e89f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step\n",
      "ResNet Model Accuracy: 0.9799\n",
      "ResNet Model F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# âœ… ResNet ëª¨ë¸ Accuracy í‰ê°€ (Keras ë‚´ì¥ evaluate í•¨ìˆ˜ ì‚¬ìš©)\n",
    "resnet_accuracy = resnet_model.evaluate(X_test, y_test, verbose=0)[1]  # [0]: loss, [1]: accuracy\n",
    "resnet_preds_test = (resnet_model.predict(X_test) > 0.5).astype(int)\n",
    "resnet_f1 = f1_score(y_test, resnet_preds_test)\n",
    "\n",
    "print(f\"ResNet Model Accuracy: {resnet_accuracy:.4f}\")\n",
    "print(f\"ResNet Model F1 Score: {resnet_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df6dbf-0772-4346-b26c-b9b630ab50d2",
   "metadata": {},
   "source": [
    "Stacking í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de56adee-4ade-428a-a810-a3de2641e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# âœ… CatBoost ëª¨ë¸ í•™ìŠµ\n",
    "catboost_model = CatBoostClassifier(n_estimators=1000, depth=6, learning_rate=0.05, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ê°’ ìƒì„± (í™•ë¥  ê°’ ì‚¬ìš©)\n",
    "catboost_train_preds = catboost_model.predict_proba(X_train)[:, 1]\n",
    "catboost_test_preds = catboost_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9164f016-372b-4a53-82a9-19bee00e34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Meta ëª¨ë¸ì„ ìœ„í•œ ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„° ìƒì„±\n",
    "X_train_meta = np.column_stack((resnet_train_preds, catboost_train_preds))\n",
    "X_test_meta = np.column_stack((resnet_test_preds, catboost_test_preds))\n",
    "\n",
    "# Meta Model (CatBoost) í•™ìŠµ\n",
    "meta_model = CatBoostClassifier(n_estimators=500, depth=6, learning_rate=0.05, verbose=0)\n",
    "meta_model.fit(X_train_meta, y_train)\n",
    "\n",
    "# Meta Model ì˜ˆì¸¡\n",
    "meta_preds_test = meta_model.predict(X_test_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88d2a5b3-535b-4801-ba2a-e23cf1f7c100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Meta Model Accuracy: 0.9754\n",
      "âœ… Meta Model F1 Score: 0.1091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "meta_acc = accuracy_score(y_test, meta_preds_test)\n",
    "meta_f1 = f1_score(y_test, meta_preds_test)\n",
    "\n",
    "print(f\"âœ… Meta Model Accuracy: {meta_acc:.4f}\")\n",
    "print(f\"âœ… Meta Model F1 Score: {meta_f1:.4f}\")\n",
    "\n",
    "# âœ… Meta Model Accuracy: 0.9754\n",
    "# âœ… Meta Model F1 Score: 0.1091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7043d141-0734-4c3e-bdfc-f15baaceccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenge Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Challenge score\n",
    "\n",
    "from helper_code import compute_challenge_score  # helper_codeì—ì„œ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "# ëª¨ë¸ ì˜ˆì¸¡ê°’ (í™•ë¥  ê¸°ë°˜)\n",
    "y_pred_prob = meta_model.predict_proba(X_test)[:, 1]  # ëª¨ë¸ì´ 1(ì–‘ì„±)ì¼ í™•ë¥  ì˜ˆì¸¡\n",
    "\n",
    "# ì‹¤ì œ ë¼ë²¨\n",
    "y_true = y_test  # ì‹¤ì œ ì •ë‹µ ë ˆì´ë¸” (0 ë˜ëŠ” 1)\n",
    "\n",
    "# âœ… Challenge Score ê³„ì‚°\n",
    "challenge_score = compute_challenge_score(y_true, y_pred_prob)\n",
    "\n",
    "print(f\"Challenge Score: {challenge_score:.3f}\")\n",
    "\n",
    "# Challenge Score: 0.159"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd26fe0-efa4-424f-a2c0-e5f28709a8b4",
   "metadata": {},
   "source": [
    "RBBB ë³€ìˆ˜ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41965f8c-6cab-4c06-8ea8-ecc0d36c90d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
