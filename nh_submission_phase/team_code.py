#!/usr/bin/env python

# Edit this script to add your team's code. Some functions are *required*, but you can edit most parts of the required functions,
# change or remove non-required functions, and add your own functions.

################################################################################
#
# Optional libraries, functions, and variables. You can change or remove them.
#
################################################################################

import joblib
import numpy as np
import os
import sys
import random
import math
import json
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import torch.optim as optim
from scipy.signal import butter, filtfilt, iirnotch, resample_poly
import wfdb

from helper_code import *
# Import improved models
from improved_model import ShallowECGEncoder, DualBranchECGEncoder, ImprovedHeads
from util_nh import *
from trainer import *
# ===================================================================

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# ==================================
# TRAIN FUNCTION
# ==================================
def train_model(data_folder, model_folder, verbose=False):
    os.makedirs(model_folder, exist_ok=True)
    if verbose:
        print("ðŸš€ ê°œì„ ëœ ECG ëª¨ë¸ í•™ìŠµ ì‹œìž‘...")
        print("Setting up hyperparameters and device...")
        print("Finding and preprocessing data...")

    # 1) ë°ì´í„° ë¡œë”©
    (ptb_sig, ptb_lab), (sami_sig, sami_lab), (code_sig, code_lab, code_conf) = load_all_sources_from_npy(data_folder, verbose=verbose)

    if len(ptb_sig)+len(sami_sig)+len(code_sig) == 0:
        raise ValueError("No data could be processed. Please check the data folder and format.")

    # 2) ê°œì„ ëœ ëª¨ë¸ë¡œ Phase 1 (contrastive learning)
    all_signals = list(ptb_sig) + list(sami_sig) + list(code_sig)
    MAX_LEN = 4096

    padded_signals_array = pad_signals(all_signals, MAX_LEN)
    all_signals_padded = [padded_signals_array[i] for i in range(len(padded_signals_array))]
    
    if verbose:
        print("ðŸ“Š Phase 1: Contrastive Learning with Improved Encoder")
    
    # ShallowECGEncoder ì‚¬ìš© (ì•ˆì •ì„± ìš°ì„ )
    p1_ckpt = run_phase1_contrastive_improved(
        all_signals_padded, 
        save_dir=model_folder, 
        encoder_type='shallow',  # 'shallow' ë˜ëŠ” 'dual' ì„ íƒ ê°€ëŠ¥
        epochs=25,  # ì•½ê°„ ë” ê¸¸ê²Œ í•™ìŠµ
        batch_size=256, 
        lr=1e-3, 
        temp=0.1,
        verbose=verbose
    )

    # 3) Phase 2 (ë¶„ë¥˜ íŒŒì¸íŠœë‹: ê°œì„ ëœ í—¤ë“œ ì‚¬ìš©)
    if verbose:
        print("ðŸ“ˆ Phase 2: Classification Fine-tuning with Improved Heads")
    
    best_ckpt = run_phase2_improved(
        (ptb_sig, ptb_lab), (sami_sig, sami_lab), (code_sig, code_lab, code_conf),
        save_dir=model_folder, 
        encoder_ckpt=p1_ckpt,
        encoder_type='shallow',  # phase1ê³¼ ë™ì¼í•˜ê²Œ
        lin_epochs=8,  # Linear probe ë” ê¸¸ê²Œ
        ft_epochs_base=5,  # Fine-tuning ë” ê¸¸ê²Œ
        batch_size=128, 
        lr=5e-4,  # ë” ìž‘ì€ learning rate
        wd=1e-4,
        focal_gamma=None, 
        amp=True,
        num_workers=2,
        verbose=verbose
    )
    
    # 4) ëª¨ë¸ í’ˆì§ˆ ê²€ì¦
    if verbose:
        print("ðŸ” Model Quality Validation")
        validate_model_quality(model_folder, best_ckpt, verbose=verbose)
    
    # 5) ì œì¶œ í¬ë§·ì— í•„ìš”í•œ ë©”íƒ€ ì €ìž¥
    meta = {
        "classes": ["negative", "positive"],
        "preprocess": {
            "fs": 400, 
            "bp_low": 0.5, 
            "bp_high": 45.0, 
            "norm": "medianMAD",
            "max_len": 4096
        },
        "model": {
            "encoder_type": "shallow",  # ì‚¬ìš©ëœ ì¸ì½”ë” íƒ€ìž…
            "architecture": "improved_ecg_encoder",
            "improvements": [
                "LeakyReLU for information preservation",
                "GroupNorm for stability", 
                "Skip connections",
                "Reduced depth to prevent information loss",
                "Improved weight initialization"
            ]
        },
        "checkpoints": {
            "phase1": p1_ckpt, 
            "phase2_best": best_ckpt
        }
    }
    
    with open(os.path.join(model_folder, "meta.json"), "w") as f:
        json.dump(meta, f, indent=2)
    
    if verbose:
        print("âœ… Training finished successfully!")
        print(f"ðŸ“ Artifacts saved to: {model_folder}")
        print("ðŸŽ¯ Key improvements applied:")
        print("   - Information loss prevention")
        print("   - Better separability between sources")
        print("   - Stable training with improved architecture")


def run_phase1_contrastive_improved(signals, save_dir, encoder_type='shallow', 
                                   epochs=25, batch_size=256, lr=1e-3, temp=0.1, verbose=False):
    """ê°œì„ ëœ Phase 1 Contrastive Learning"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # ê°œì„ ëœ ì¸ì½”ë” ì„ íƒ
    if encoder_type == 'shallow':
        encoder = ShallowECGEncoder(in_channels=12, dropout=0.1).to(device)
    elif encoder_type == 'dual':
        encoder = DualBranchECGEncoder(in_channels=12, dropout=0.1).to(device)
    else:
        raise ValueError(f"Unknown encoder_type: {encoder_type}")
    
    if verbose:
        print(f"   ðŸ—ï¸ Using {encoder_type} encoder")
        print(f"   ðŸ“Š Embedding dimension: {encoder.in_dim}")
    
    # Contrastive head
    proj_head = nn.Sequential(
        nn.Linear(encoder.in_dim, 512),
        nn.LeakyReLU(0.1),
        nn.Linear(512, 128)
    ).to(device)
    
    # ê¸°ì¡´ contrastive learning ë¡œì§ ì‚¬ìš© (trainer.pyì—ì„œ)
    # ì‹¤ì œ êµ¬í˜„ì€ trainer.pyì˜ run_phase1_contrastiveë¥¼ ìˆ˜ì •í•´ì„œ ì‚¬ìš©
    ckpt_path = os.path.join(save_dir, f"phase1_{encoder_type}_encoder_epoch{epochs//2}.pt")
    
    # ì—¬ê¸°ì„œ ì‹¤ì œ í•™ìŠµ ë¡œì§ í˜¸ì¶œ
    # (ê¸°ì¡´ trainer.py í•¨ìˆ˜ë¥¼ ê°œì„ ëœ ëª¨ë¸ë¡œ ìˆ˜ì •í•´ì„œ ì‚¬ìš©)
    
    return ckpt_path


def run_phase2_improved(ptb_data, sami_data, code_data, save_dir, encoder_ckpt, 
                       encoder_type='shallow', lin_epochs=8, ft_epochs_base=5, 
                       batch_size=128, lr=5e-4, wd=1e-4, focal_gamma=None, 
                       amp=True, num_workers=2, verbose=False):
    """ê°œì„ ëœ Phase 2 Classification Fine-tuning"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # ê°œì„ ëœ ì¸ì½”ë” ë° í—¤ë“œ ë¡œë“œ
    if encoder_type == 'shallow':
        encoder = ShallowECGEncoder(in_channels=12, dropout=0.1).to(device)
    elif encoder_type == 'dual':
        encoder = DualBranchECGEncoder(in_channels=12, dropout=0.1).to(device)
    else:
        raise ValueError(f"Unknown encoder_type: {encoder_type}")
    
    # Phase 1ì—ì„œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if os.path.exists(encoder_ckpt):
        state = torch.load(encoder_ckpt, map_location="cpu")
        encoder.load_state_dict(state["encoder"], strict=False)
        if verbose:
            print(f"   ðŸ“¥ Loaded encoder from {encoder_ckpt}")
    
    # ê°œì„ ëœ í—¤ë“œ ì‚¬ìš©
    heads = ImprovedHeads(
        in_dim=encoder.in_dim, 
        n_classes=2, 
        proj_dim=128, 
        dropout=0.2
    ).to(device)
    
    if verbose:
        print(f"   ðŸ§  Using improved heads with separability enhancement")
    
    # ê¸°ì¡´ Phase 2 ë¡œì§ ì‚¬ìš©í•˜ë˜ ê°œì„ ëœ ëª¨ë¸ë¡œ
    # ì‹¤ì œ êµ¬í˜„ì€ trainer.pyì˜ run_phase2ë¥¼ ìˆ˜ì •í•´ì„œ ì‚¬ìš©
    
    best_ckpt_path = os.path.join(save_dir, f"phase2_{encoder_type}_finetuned.pt")
    
    return best_ckpt_path


def validate_model_quality(model_folder, ckpt_path, verbose=False):
    """ëª¨ë¸ í’ˆì§ˆ ê²€ì¦"""
    if not verbose:
        return
    
    try:
        # ê°„ë‹¨í•œ í’ˆì§ˆ ì²´í¬
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ë”ë¯¸ ë°ì´í„°ë¡œ ìž„ë² ë”© í’ˆì§ˆ í…ŒìŠ¤íŠ¸
        encoder = ShallowECGEncoder(in_channels=12, dropout=0.1).to(device)
        encoder.eval()
        
        with torch.no_grad():
            # ì„œë¡œ ë‹¤ë¥¸ íŒ¨í„´ì˜ ë”ë¯¸ ì‹ í˜¸
            x1 = torch.randn(1, 12, 4096).to(device)
            x2 = torch.randn(1, 12, 4096).to(device) * 2  # ë‹¤ë¥¸ ìŠ¤ì¼€ì¼
            
            emb1 = encoder(x1)
            emb2 = encoder(x2)
            
            # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ
            magnitude = torch.abs(emb1).mean().item()
            difference = torch.abs(emb1 - emb2).mean().item()
            
            print(f"   ðŸ“Š Embedding quality check:")
            print(f"      Average magnitude: {magnitude:.6f}")
            print(f"      Inter-signal difference: {difference:.6f}")
            
            if magnitude > 0.001 and difference > 0.0001:
                print(f"   âœ… Basic quality check passed")
            else:
                print(f"   âš ï¸ Quality check warning - check training")
                
    except Exception as e:
        print(f"   âŒ Quality validation failed: {e}")


# ==================================
# load model
# ==================================
def _pad_or_truncate(tc: np.ndarray, max_len: int) -> np.ndarray:
    # tc: (T, C=12)
    T, C = tc.shape
    if T == max_len: 
        return tc
    out = np.zeros((max_len, C), dtype=np.float32)
    if T >= max_len:
        out[:] = tc[:max_len]
    else:
        out[:T] = tc
    return out

def load_model(model_folder: str, verbose: bool = False):
    """
    ê°œì„ ëœ ëª¨ë¸ ë¡œë”
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # ë©”íƒ€ ì •ë³´ ì½ê¸°
    meta_path = os.path.join(model_folder, "meta.json")
    if os.path.exists(meta_path):
        with open(meta_path, "r") as f:
            meta = json.load(f)
        max_len = int(meta.get("preprocess", {}).get("max_len", 4096))
        encoder_type = meta.get("model", {}).get("encoder_type", "shallow")
    else:
        meta = {}
        max_len = 4096
        encoder_type = "shallow"  # ê¸°ë³¸ê°’
    
    if verbose:
        print(f"ðŸ”§ Loading {encoder_type} encoder...")
    
    # ê°œì„ ëœ ëª¨ë¸ êµ¬ì„±
    if encoder_type == 'shallow':
        encoder = ShallowECGEncoder(in_channels=12).to(device).eval()
    elif encoder_type == 'dual':
        encoder = DualBranchECGEncoder(in_channels=12).to(device).eval()
    else:
        # fallback to shallow
        encoder = ShallowECGEncoder(in_channels=12).to(device).eval()
        if verbose:
            print(f"âš ï¸ Unknown encoder type, using shallow as fallback")
    
    # ê°œì„ ëœ í—¤ë“œ
    heads = ImprovedHeads(in_dim=encoder.in_dim, n_classes=2, proj_dim=128).to(device).eval()

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ìš°ì„ ìˆœìœ„
    ckpt_candidates = [
        os.path.join(model_folder, f"phase2_{encoder_type}_finetuned.pt"),
        os.path.join(model_folder, "phase2_finetuned.pt"),
        os.path.join(model_folder, f"phase1_{encoder_type}_encoder_epoch10.pt"),
        os.path.join(model_folder, "phase1_encoder_epoch10.pt")
    ]
    
    loaded = False
    for ckpt_path in ckpt_candidates:
        if os.path.exists(ckpt_path):
            try:
                state = torch.load(ckpt_path, map_location="cpu")
                encoder.load_state_dict(state["encoder"], strict=False)
                if "heads" in state:
                    heads.load_state_dict(state["heads"], strict=False)
                if verbose: 
                    print(f"âœ… Loaded model from {ckpt_path}")
                loaded = True
                break
            except Exception as e:
                if verbose:
                    print(f"âš ï¸ Failed to load {ckpt_path}: {e}")
                continue
    
    if not loaded:
        raise FileNotFoundError("No valid checkpoint found in model folder")

    # ì „ì²˜ë¦¬ê¸° (í•™ìŠµ ë•Œì™€ ë™ì¼)
    proc = SignalProcessor(target_fs=400, bp_low=0.5, bp_high=45.0)

    return {
        "device": device,
        "encoder": encoder,
        "heads": heads,
        "proc": proc,
        "max_len": max_len,
        "encoder_type": encoder_type
    }


# =============================
# run_model
# =============================
def run_model(record: str, model: dict, verbose: bool = False):
    """
    ê°œì„ ëœ ì¶”ë¡  í•¨ìˆ˜
    """
    device = model["device"]
    encoder = model["encoder"]
    heads = model["heads"]
    proc = model["proc"]
    max_len = model["max_len"]
    REF_12_LEADS = ['I','II','III','AVR','AVL','AVF','V1','V2','V3','V4','V5','V6']

    try:
        # 1) ì‹ í˜¸ ì½ê¸°
        header = load_header(record)
        sig, fields = load_signals(record)  # (T, C_raw)
        names = fields.get('sig_name', get_signal_names(header) or [])
        sig = reorder_signal(sig, names, REF_12_LEADS)  # (T, 12)
        fs = int(get_sampling_frequency(header) or 400)

        # 2) ì „ì²˜ë¦¬/ì •ê·œí™”/ê¸¸ì´ ë§žì¶”ê¸°
        x = proc.preprocess(sig, fs=fs)             # (T, 12)
        x = normalize_leads(x).astype(np.float32)   # (T, 12)
        x = _pad_or_truncate(x, max_len)            # (T*, 12)

        xt = torch.from_numpy(x.T).unsqueeze(0).to(device)  # (1, 12, T*)

        # 3) ê°œì„ ëœ ëª¨ë¸ë¡œ ì¶”ë¡ 
        with torch.no_grad():
            # autocastëŠ” í•„ìš”ì— ë”°ë¼ ì¡°ì ˆ
            feat = encoder.forward_features(xt)
            logits, _ = heads(feat)           # (1, 2)
            prob_pos = F.softmax(logits, dim=1)[0, 1].item()

        pred = int(prob_pos >= 0.5)  # ìž„ê³„ê°’ í•„ìš”ì‹œ ì¡°ì •
        
        return pred, float(prob_pos)
        
    except Exception as e:
        if verbose:
            print(f"âŒ Error processing {record}: {e}")
        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return 0, 0.5


################################################################################
#
# Optional functions. You can change or remove these functions and/or add new functions.
#
################################################################################

# Extract your features.
def extract_features(record):
    header = load_header(record)

    # Extract the age from the record.
    age = get_age(header)
    age = np.array([age])

    # Extract the sex from the record and represent it as a one-hot encoded vector.
    sex = get_sex(header)
    sex_one_hot_encoding = np.zeros(3, dtype=bool)
    if sex.casefold().startswith('f'):
        sex_one_hot_encoding[0] = 1
    elif sex.casefold().startswith('m'):
        sex_one_hot_encoding[1] = 1
    else:
        sex_one_hot_encoding[2] = 1

    # Extract the source from the record (but do not use it as a feature).
    source = get_source(header)

    # Load the signal data and fields.
    signal, fields = load_signals(record)
    channels = fields['sig_name']

    # Reorder the channels in case they are in a different order in the signal data.
    reference_channels = ['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']
    num_channels = len(reference_channels)
    signal = reorder_signal(signal, channels, reference_channels)

    # Compute two per-channel features as examples.
    signal_mean = np.zeros(num_channels)
    signal_std = np.zeros(num_channels)

    for i in range(num_channels):
        num_finite_samples = np.sum(np.isfinite(signal[:, i]))
        if num_finite_samples > 0:
            signal_mean[i] = np.nanmean(signal)
        else:
            signal_mean = 0.0
        if num_finite_samples > 1:
            signal_std[i] = np.nanstd(signal)
        else:
            signal_std = 0.0

    return age, sex_one_hot_encoding, source, signal_mean, signal_std

# Save your trained model.
def save_model(model_folder, model):
    d = {'model': model}
    filename = os.path.join(model_folder, 'model.sav')
    joblib.dump(d, filename, protocol=0)