{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f3dc2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'lead_gate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Data/nh25/ECG/nh_submission3/model/phase1_encoder_epoch10.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# state_dict가 아니라 객체로 저장했을 경우\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# alpha 값 확인\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m alpha_values \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlead_gate\u001b[49m\u001b[38;5;241m.\u001b[39malpha\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(alpha_values, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLead \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'lead_gate'"
     ]
    }
   ],
   "source": [
    "# 예: 학습 완료 모델 로드\n",
    "encoder = torch.load(\"/Data/nh25/ECG/nh_submission3/model/phase1_encoder_epoch10.pt\")  # state_dict가 아니라 객체로 저장했을 경우\n",
    "\n",
    "# alpha 값 확인\n",
    "alpha_values = encoder.lead_gate.alpha.detach().cpu().numpy().squeeze()\n",
    "for i, val in enumerate(alpha_values, start=1):\n",
    "    print(f\"Lead {i}: {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae89ded1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EnhancedECGEncoder:\n\tMissing key(s) in state_dict: \"lead_gate.alpha\", \"stem.0.conv_small.weight\", \"stem.0.conv_small.bias\", \"stem.0.conv_medium.weight\", \"stem.0.conv_medium.bias\", \"stem.0.conv_large.weight\", \"stem.0.conv_large.bias\", \"stem.0.bn.weight\", \"stem.0.bn.bias\", \"stem.0.bn.running_mean\", \"stem.0.bn.running_var\", \"layer1.0.0.weight\", \"layer1.0.1.weight\", \"layer1.0.1.bias\", \"layer1.0.1.running_mean\", \"layer1.0.1.running_var\", \"layer1.0.3.weight\", \"layer1.0.4.weight\", \"layer1.0.4.bias\", \"layer1.0.4.running_mean\", \"layer1.0.4.running_var\", \"layer1.1.0.weight\", \"layer1.1.1.weight\", \"layer1.1.1.bias\", \"layer1.1.1.running_mean\", \"layer1.1.1.running_var\", \"layer1.1.3.weight\", \"layer1.1.4.weight\", \"layer1.1.4.bias\", \"layer1.1.4.running_mean\", \"layer1.1.4.running_var\", \"tatt1.conv.weight\", \"tatt1.conv.bias\", \"layer2.0.0.weight\", \"layer2.0.1.weight\", \"layer2.0.1.bias\", \"layer2.0.1.running_mean\", \"layer2.0.1.running_var\", \"layer2.0.3.weight\", \"layer2.0.4.weight\", \"layer2.0.4.bias\", \"layer2.0.4.running_mean\", \"layer2.0.4.running_var\", \"layer2.1.0.weight\", \"layer2.1.1.weight\", \"layer2.1.1.bias\", \"layer2.1.1.running_mean\", \"layer2.1.1.running_var\", \"layer2.1.3.weight\", \"layer2.1.4.weight\", \"layer2.1.4.bias\", \"layer2.1.4.running_mean\", \"layer2.1.4.running_var\", \"tatt2.conv.weight\", \"tatt2.conv.bias\", \"layer3.0.0.weight\", \"layer3.0.1.weight\", \"layer3.0.1.bias\", \"layer3.0.1.running_mean\", \"layer3.0.1.running_var\", \"layer3.0.3.weight\", \"layer3.0.4.weight\", \"layer3.0.4.bias\", \"layer3.0.4.running_mean\", \"layer3.0.4.running_var\", \"layer3.1.0.weight\", \"layer3.1.1.weight\", \"layer3.1.1.bias\", \"layer3.1.1.running_mean\", \"layer3.1.1.running_var\", \"layer3.1.3.weight\", \"layer3.1.4.weight\", \"layer3.1.4.bias\", \"layer3.1.4.running_mean\", \"layer3.1.4.running_var\", \"tatt3.conv.weight\", \"tatt3.conv.bias\", \"lstm_block.lstm.weight_ih_l0\", \"lstm_block.lstm.weight_hh_l0\", \"lstm_block.lstm.bias_ih_l0\", \"lstm_block.lstm.bias_hh_l0\", \"lstm_block.lstm.weight_ih_l0_reverse\", \"lstm_block.lstm.weight_hh_l0_reverse\", \"lstm_block.lstm.bias_ih_l0_reverse\", \"lstm_block.lstm.bias_hh_l0_reverse\", \"lstm_block.lstm.weight_ih_l1\", \"lstm_block.lstm.weight_hh_l1\", \"lstm_block.lstm.bias_ih_l1\", \"lstm_block.lstm.bias_hh_l1\", \"lstm_block.lstm.weight_ih_l1_reverse\", \"lstm_block.lstm.weight_hh_l1_reverse\", \"lstm_block.lstm.bias_ih_l1_reverse\", \"lstm_block.lstm.bias_hh_l1_reverse\", \"lstm_block.proj.weight\", \"lstm_block.proj.bias\", \"lstm_block.norm.weight\", \"lstm_block.norm.bias\". \n\tUnexpected key(s) in state_dict: \"encoder\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil_nh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m encoder \u001b[38;5;241m=\u001b[39m EnhancedECGEncoder(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Data/nh25/ECG/nh_submission3/model/phase1_encoder_epoch10.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# alpha 확인\u001b[39;00m\n\u001b[1;32m      9\u001b[0m alpha_values \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mlead_gate\u001b[38;5;241m.\u001b[39malpha\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EnhancedECGEncoder:\n\tMissing key(s) in state_dict: \"lead_gate.alpha\", \"stem.0.conv_small.weight\", \"stem.0.conv_small.bias\", \"stem.0.conv_medium.weight\", \"stem.0.conv_medium.bias\", \"stem.0.conv_large.weight\", \"stem.0.conv_large.bias\", \"stem.0.bn.weight\", \"stem.0.bn.bias\", \"stem.0.bn.running_mean\", \"stem.0.bn.running_var\", \"layer1.0.0.weight\", \"layer1.0.1.weight\", \"layer1.0.1.bias\", \"layer1.0.1.running_mean\", \"layer1.0.1.running_var\", \"layer1.0.3.weight\", \"layer1.0.4.weight\", \"layer1.0.4.bias\", \"layer1.0.4.running_mean\", \"layer1.0.4.running_var\", \"layer1.1.0.weight\", \"layer1.1.1.weight\", \"layer1.1.1.bias\", \"layer1.1.1.running_mean\", \"layer1.1.1.running_var\", \"layer1.1.3.weight\", \"layer1.1.4.weight\", \"layer1.1.4.bias\", \"layer1.1.4.running_mean\", \"layer1.1.4.running_var\", \"tatt1.conv.weight\", \"tatt1.conv.bias\", \"layer2.0.0.weight\", \"layer2.0.1.weight\", \"layer2.0.1.bias\", \"layer2.0.1.running_mean\", \"layer2.0.1.running_var\", \"layer2.0.3.weight\", \"layer2.0.4.weight\", \"layer2.0.4.bias\", \"layer2.0.4.running_mean\", \"layer2.0.4.running_var\", \"layer2.1.0.weight\", \"layer2.1.1.weight\", \"layer2.1.1.bias\", \"layer2.1.1.running_mean\", \"layer2.1.1.running_var\", \"layer2.1.3.weight\", \"layer2.1.4.weight\", \"layer2.1.4.bias\", \"layer2.1.4.running_mean\", \"layer2.1.4.running_var\", \"tatt2.conv.weight\", \"tatt2.conv.bias\", \"layer3.0.0.weight\", \"layer3.0.1.weight\", \"layer3.0.1.bias\", \"layer3.0.1.running_mean\", \"layer3.0.1.running_var\", \"layer3.0.3.weight\", \"layer3.0.4.weight\", \"layer3.0.4.bias\", \"layer3.0.4.running_mean\", \"layer3.0.4.running_var\", \"layer3.1.0.weight\", \"layer3.1.1.weight\", \"layer3.1.1.bias\", \"layer3.1.1.running_mean\", \"layer3.1.1.running_var\", \"layer3.1.3.weight\", \"layer3.1.4.weight\", \"layer3.1.4.bias\", \"layer3.1.4.running_mean\", \"layer3.1.4.running_var\", \"tatt3.conv.weight\", \"tatt3.conv.bias\", \"lstm_block.lstm.weight_ih_l0\", \"lstm_block.lstm.weight_hh_l0\", \"lstm_block.lstm.bias_ih_l0\", \"lstm_block.lstm.bias_hh_l0\", \"lstm_block.lstm.weight_ih_l0_reverse\", \"lstm_block.lstm.weight_hh_l0_reverse\", \"lstm_block.lstm.bias_ih_l0_reverse\", \"lstm_block.lstm.bias_hh_l0_reverse\", \"lstm_block.lstm.weight_ih_l1\", \"lstm_block.lstm.weight_hh_l1\", \"lstm_block.lstm.bias_ih_l1\", \"lstm_block.lstm.bias_hh_l1\", \"lstm_block.lstm.weight_ih_l1_reverse\", \"lstm_block.lstm.weight_hh_l1_reverse\", \"lstm_block.lstm.bias_ih_l1_reverse\", \"lstm_block.lstm.bias_hh_l1_reverse\", \"lstm_block.proj.weight\", \"lstm_block.proj.bias\", \"lstm_block.norm.weight\", \"lstm_block.norm.bias\". \n\tUnexpected key(s) in state_dict: \"encoder\". "
     ]
    }
   ],
   "source": [
    "# 구조 먼저 만들고 state_dict 로드\n",
    "from model import *\n",
    "from util_nh import *\n",
    "\n",
    "encoder = EnhancedECGEncoder(in_channels=12)\n",
    "encoder.load_state_dict(torch.load(\"/Data/nh25/ECG/nh_submission3/model/phase1_encoder_epoch10.pt\"))\n",
    "\n",
    "# alpha 확인\n",
    "alpha_values = encoder.lead_gate.alpha.detach().cpu().numpy().squeeze()\n",
    "print(alpha_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db2d6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: []\n",
      "Unexpected: []\n",
      "Has alpha?: True\n",
      "alpha: [1.3222833  1.5937221  0.6384284  1.6823562  0.8638819  1.147478\n",
      " 0.16227692 0.1362344  0.1767093  0.22961861 0.42116055 0.34676102]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def load_encoder_and_get_alpha(ckpt_path, in_channels=12, device=\"cpu\"):\n",
    "    # 1) 체크포인트 로드\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    # 2) 실제 state_dict 꺼내기\n",
    "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        sd = ckpt[\"state_dict\"]\n",
    "    elif isinstance(ckpt, dict) and \"encoder\" in ckpt and isinstance(ckpt[\"encoder\"], dict):\n",
    "        sd = ckpt[\"encoder\"]\n",
    "    else:\n",
    "        sd = ckpt  # 이미 순수 state_dict인 경우\n",
    "\n",
    "    # 3) prefix 정리\n",
    "    new_sd = {}\n",
    "    for k, v in sd.items():\n",
    "        if k.startswith(\"module.\"):\n",
    "            k = k[len(\"module.\"):]\n",
    "        if k.startswith(\"encoder.\"):\n",
    "            k = k[len(\"encoder.\"):]\n",
    "        new_sd[k] = v\n",
    "\n",
    "    # 4) 현재 코드의 모델 인스턴스 생성\n",
    "    enc = EnhancedECGEncoder(in_channels=in_channels).to(device)\n",
    "\n",
    "    # 5) state_dict 로드 (strict=False로 아키텍처 차이를 견딤)\n",
    "    incompatible = enc.load_state_dict(new_sd, strict=False)\n",
    "\n",
    "    # 6) alpha 존재 여부 확인\n",
    "    alpha_ok = hasattr(enc, \"lead_gate\") and hasattr(enc.lead_gate, \"alpha\")\n",
    "    alpha_tensor = enc.lead_gate.alpha.detach().cpu() if alpha_ok else None\n",
    "\n",
    "    return enc, incompatible, alpha_ok, alpha_tensor\n",
    "\n",
    "# 사용 예시\n",
    "enc, inc, alpha_ok, alpha = load_encoder_and_get_alpha(\n",
    "    \"/Data/nh25/ECG/nh_submission3/model/phase1_encoder_epoch10.pt\",\n",
    "    in_channels=12, device=\"cpu\"\n",
    ")\n",
    "\n",
    "print(\"Missing:\", inc.missing_keys)\n",
    "print(\"Unexpected:\", inc.unexpected_keys)\n",
    "print(\"Has alpha?:\", alpha_ok)\n",
    "\n",
    "if alpha_ok:\n",
    "    print(\"alpha:\", alpha.numpy().squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8905b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43malpha_values\u001b[49m\n\u001b[1;32m      2\u001b[0m order \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39margsort()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 큰 값부터\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m order:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha_values' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
